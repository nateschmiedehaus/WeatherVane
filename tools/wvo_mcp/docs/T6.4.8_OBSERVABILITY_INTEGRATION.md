# T6.4.8: Observability & Resource Budgets During Upgrade

## Summary

This task implements comprehensive observability and resource budget management for worker calls during upgrades. The implementation ensures:

- **OTel Span Emission**: Every worker call is instrumented with OpenTelemetry spans containing timing, lane, task, and outcome metadata
- **Concurrency Guardrails**: Lane-aware rate limiting prevents resource exhaustion (e.g., 8 concurrent tool calls, 16 file reads, 4 file writes)
- **Timeout Enforcement**: Configurable per-call timeouts with escalation (warning → hard kill)
- **Memory Monitoring**: RSS and heap usage tracking with configurable limits
- **Structured JSON Logging**: Comprehensive metrics and audit trails for every worker call
- **Zero-Loss Integration**: Works seamlessly with existing observability infrastructure

## Implementation Details

### 1. Resource Budgets Module (`resource_budgets.ts`)

**Core Components:**

| Component | Purpose |
|-----------|---------|
| `ResourceBudgetManager` | Central coordinator for all resource controls |
| `LaneManager` | Per-lane concurrency tracking (tool_call, file_read, file_write, critic) |
| `TimeoutManager` | Request-level timeout enforcement with escalation |
| `MemoryMonitor` | RSS and heap usage tracking |
| `Metrics` | Accumulated telemetry for observability |

**Key Configuration:**

```typescript
interface ResourceBudgetConfig {
  maxRssMb: 512;                           // Max RSS memory
  heapWarningMb: 400;                      // Heap warning threshold
  laneConcurrencyLimits: {
    tool_call: 8,                          // Max concurrent tool calls
    file_read: 16,                         // Max concurrent file reads
    file_write: 4,                         // Max concurrent file writes
    critic: 3,                             // Max concurrent critics
    forecast_model: 1                      // Single-threaded models
  };
  globalConcurrencyLimit: 32;              // Global limit across all lanes
  defaultTimeoutMs: 300000;                // 5 minutes default
  timeoutEscalationFactor: 1.5;            // 1.5x multiplier before hard kill
  enableMemoryGuards: true;                // Enable RSS/heap checks
  enableSpanEmission: true;                // Enable OTel spans
  spanSampleRate: 1.0;                     // Sample rate (0.0-1.0)
}
```

**Usage:**

```typescript
import { getResourceBudgetManager } from "./resource_budgets.js";

const manager = getResourceBudgetManager({
  maxRssMb: 1024,
  globalConcurrencyLimit: 64
});

// Acquire a slot for a worker call
const context = await manager.acquireSlot(
  "task-123",           // Task ID
  "tool_call",          // Lane
  300000,               // Optional: timeout in ms
  { userId: "user-1" }  // Optional: metadata
);

if (!context) {
  // Resource limits exceeded
  console.error("Resource limit rejected worker call");
  return;
}

try {
  // Do work
  const result = await runExpensiveOperation();

  // Release slot with success
  manager.releaseSlot(context, true);
} catch (error) {
  // Release slot with failure
  manager.releaseSlot(context, false, error);
  throw error;
}

// Get metrics
const metrics = manager.getMetrics();
const stats = manager.getStatistics();
const memory = manager.getMemorySnapshot();
const concurrency = manager.getConcurrencyStatus();
```

### 2. Worker Call Wrapper (`worker_call_wrapper.ts`)

High-level API for wrapping worker calls with observability:

**Basic Wrapper:**

```typescript
import { withWorkerCallObservability } from "./worker_call_wrapper.js";

const result = await withWorkerCallObservability(
  "task-123",
  async () => {
    return await router.runTool("forecast_stitch", input);
  },
  {
    lane: "critic",
    timeoutMs: 600000,
    metadata: { toolName: "forecast_stitch", inputSize: 1024 }
  }
);
```

**Batch Operations:**

```typescript
const wrapper = createBatchWorkerCallWrapper(
  "task-123",
  "file_write",
  { timeoutMs: 600000 }
);

try {
  await wrapper.init();

  for (const item of items) {
    const result = await wrapper.execute(() => processItem(item));
  }
} finally {
  wrapper.release(true);  // or (false, error) on failure
}
```

**Request Scopes:**

```typescript
// Share timeout across multiple calls
await withRequestScope(
  "task-123",
  async (scope) => {
    // Multiple operations with shared timeout
    const result1 = await operation1();
    const result2 = await operation2();
    const result3 = await operation3();
    return [result1, result2, result3];
  },
  { lane: "tool_call", timeoutMs: 600000 }
);
```

### 3. OTel Span Integration

All worker calls emit spans with comprehensive metadata:

**Span Structure:**

```json
{
  "name": "worker_call:tool_call",
  "attributes": {
    "service": "weathervane-orchestrator",
    "version": "1.0.0",
    "environment": "production",
    "taskId": "task-123",
    "lane": "tool_call",
    "userId": "user-1"
  },
  "events": [
    {
      "name": "acquired_slot",
      "globalConcurrency": 4,
      "laneConcurrency": 2
    },
    {
      "name": "execution_started",
      "taskId": "task-123"
    },
    {
      "name": "execution_succeeded"
    }
  ],
  "duration": 1234
}
```

**Span Events:**

- `acquired_slot`: Resource slot acquired, includes concurrency counts
- `execution_started`: Worker call began execution
- `execution_succeeded`: Call completed successfully
- `call_completed`: Summary of call with status and duration
- `batch_started`: Batch operation started
- `batch_item_processed`: Single item in batch processed
- `batch_item_failed`: Item processing failed
- `batch_completed`: Batch finished with item/error counts
- `timeout`: Timeout warning or escalation triggered

### 4. Timeout Escalation

Two-phase timeout enforcement:

**Phase 1: Warning (default timeout)**
- Logged as warning
- Span event recorded
- Opportunity for graceful shutdown
- No forced termination

**Phase 2: Escalation (timeout × escalationFactor)**
- Logged as error
- Force termination begins
- Resource cleanup triggers
- Error recorded in span

Example:
- Default timeout: 300s (5 min)
- Escalation factor: 1.5×
- Warning at: 300s
- Hard kill at: 450s (300 × 1.5)

### 5. Lane Concurrency Control

**Predefined Lanes:**

| Lane | Limit | Purpose |
|------|-------|---------|
| `tool_call` | 8 | MCP tool invocations |
| `file_read` | 16 | File system reads |
| `file_write` | 4 | File system writes |
| `critic` | 3 | Critic executions |
| `forecast_model` | 1 | Model training/inference |

**Custom Lanes:**

```typescript
const config: Partial<ResourceBudgetConfig> = {
  laneConcurrencyLimits: {
    custom_lane: 5,
    // ... other lanes
  }
};
```

### 6. Memory Monitoring

**Guarded Operations:**

```typescript
// Memory snapshot includes:
{
  rssMb: 256.45,        // Resident set size in MB
  heapTotalMb: 400,     // Total allocated heap
  heapUsedMb: 256,      // Heap in use
  externalMb: 10.5,     // External memory
  arrayBuffersMb: 2.3,  // ArrayBuffer memory
  timestamp: "2025-10-22T21:00:00.000Z"
}
```

**Guards:**

- RSS exceeds `maxRssMb`: Slot acquisition rejected
- Heap exceeds `heapWarningMb`: Warning logged, slot acquisition allowed
- Disable with `enableMemoryGuards: false`

### 7. Metrics & Statistics

**Per-Call Metrics:**

```typescript
interface WorkerCallMetrics {
  callId: string;
  taskId: string;
  lane: Lane;
  durationMs: number;
  success: boolean;
  errorType?: string;
  rssStartMb: number;
  rssEndMb: number;
  rssDeltaMb: number;
  heapStartMb: number;
  heapEndMb: number;
  heapDeltaMb: number;
  concurrentCallsAtStart: number;
  concurrentCallsAtEnd: number;
  timeoutReached: boolean;
  timestamp: string;
}
```

**Aggregated Statistics:**

```typescript
const stats = manager.getStatistics();
// {
//   totalCalls: 1250,
//   successCount: 1220,
//   failureCount: 30,
//   averageDurationMs: 1342,
//   averageRssDeltaMb: 2.5,
//   maxConcurrentCalls: 28,
//   timeoutCount: 3
// }
```

## Integration with Existing Infrastructure

### With OTel Spans (`otel_spans.ts`)

The module uses existing span infrastructure:

```typescript
import {
  startOtelSpan,
  endOtelSpan,
  recordSpanEvent,
  recordSpanError,
  recordOperationMetrics
} from "../telemetry/otel_spans.js";

// All spans are automatically registered with the global tracing system
```

### With Logger (`logger.js`)

Structured logging with context:

```typescript
import { logInfo, logWarning, logError } from "../telemetry/logger.js";

logInfo("Worker call slot acquired", {
  contextId,
  taskId,
  lane,
  globalConcurrency: this.globalActive.size
});
```

### With Worker Manager (`worker_manager.ts`)

Future integration point: Wrap worker manager's `call()` method:

```typescript
// In worker_manager.ts
async call<T>(options: WorkerCallOptions): Promise<T> {
  return withWorkerCallObservability(
    options.taskId || "unknown",
    () => this._executeCall(options),
    { lane: "worker_call", metadata: options }
  );
}
```

### With Tool Router (`tool_router.ts`)

Wrap tool execution:

```typescript
// In tool_router.ts
async runTool(name: string, input?: unknown): Promise<unknown> {
  return withWorkerCallObservability(
    this.session.taskId || "unknown",
    () => this._executeToolDirect(name, input),
    { lane: "tool_call", metadata: { toolName: name, inputSize: JSON.stringify(input).length } }
  );
}
```

## Testing

### Unit Tests

Comprehensive test coverage in `resource_budgets.test.ts`:

- ✅ Slot acquisition and release
- ✅ Concurrency limit enforcement
- ✅ Lane independence
- ✅ Memory monitoring
- ✅ Timeout management
- ✅ Metrics recording
- ✅ Statistics aggregation
- ✅ OTel span integration
- ✅ Error handling

### Integration Tests

Test scenarios in `worker_call_wrapper.test.ts`:

- ✅ Basic wrapper execution
- ✅ Async operations
- ✅ Error propagation
- ✅ Custom timeouts
- ✅ Metadata tracking
- ✅ Resource limit rejection
- ✅ Graceful degradation
- ✅ Batch operations
- ✅ Request scopes
- ✅ Lane categorization
- ✅ Rapid sequential calls
- ✅ Mixed lanes
- ✅ Nested request scopes

**Run Tests:**

```bash
npm run test -- tools/wvo_mcp/src/observability/
```

## Monitoring & Observability

### Emit Metrics to External Systems

```typescript
const manager = getResourceBudgetManager();

// Poll metrics periodically
setInterval(() => {
  const stats = manager.getStatistics();
  const memory = manager.getMemorySnapshot();
  const concurrency = manager.getConcurrencyStatus();

  // Send to monitoring system
  emitMetrics({
    "worker.calls.total": stats.totalCalls,
    "worker.calls.success": stats.successCount,
    "worker.calls.failure": stats.failureCount,
    "worker.calls.timeout": stats.timeoutCount,
    "worker.duration.avg_ms": stats.averageDurationMs,
    "memory.rss_mb": memory.rssMb,
    "memory.heap_used_mb": memory.heapUsedMb,
    "concurrency.global.active": concurrency.global.active,
    "concurrency.global.limit": concurrency.global.limit,
    // Per-lane metrics
    "concurrency.lane.tool_call.active": concurrency.lanes.tool_call.active,
    "concurrency.lane.file_read.active": concurrency.lanes.file_read.active,
    // ...
  });
}, 30000);
```

### Alerting Rules

**Critical Alerts:**

- RSS memory > 90% of limit
- Global concurrency > 90% of limit
- Timeout escalations occurring
- Error rate > 5%

**Warning Alerts:**

- Heap usage > `heapWarningMb`
- Lane concurrency > 80% of limit
- Average duration increasing

## Configuration Examples

### Development Environment

```typescript
const config = {
  maxRssMb: 256,                    // Tighter memory
  globalConcurrencyLimit: 8,        // Lower concurrency
  enableMemoryGuards: true,
  enableSpanEmission: false,        // No span overhead
  spanSampleRate: 0.1               // 10% sampling
};
```

### Staging Environment

```typescript
const config = {
  maxRssMb: 512,
  globalConcurrencyLimit: 32,
  enableMemoryGuards: true,
  enableSpanEmission: true,
  spanSampleRate: 0.5               // 50% sampling
};
```

### Production Environment

```typescript
const config = {
  maxRssMb: 1024,                   // Generous for peak loads
  globalConcurrencyLimit: 64,
  laneConcurrencyLimits: {
    tool_call: 16,
    file_read: 32,
    file_write: 8,
    critic: 6,
    forecast_model: 1
  },
  defaultTimeoutMs: 600000,         // 10 minutes
  enableMemoryGuards: true,
  enableSpanEmission: true,
  spanSampleRate: 1.0               // Full sampling
};
```

## Error Handling & Graceful Degradation

### Resource Limit Exceeded

**With `throwOnResourceLimitExceeded: true`:**
```typescript
// Throws error immediately
await withWorkerCallObservability(..., {
  throwOnResourceLimitExceeded: true
});
// → Error: "Resource limit exceeded..."
```

**With `throwOnResourceLimitExceeded: false`:**
```typescript
// Executes without resource guards
const result = await withWorkerCallObservability(..., {
  throwOnResourceLimitExceeded: false
});
// Returns result (unguarded)
```

## Migration Guide

### Wrapping Existing Worker Calls

**Before:**
```typescript
const result = await router.runTool("forecast_stitch", input);
```

**After:**
```typescript
const result = await withWorkerCallObservability(
  taskId,
  () => router.runTool("forecast_stitch", input),
  { lane: "critic", metadata: { toolName: "forecast_stitch" } }
);
```

### Phase 1: Internal Only
Wrap only critical paths (critics, models).

### Phase 2: All Tool Calls
Extend to all MCP tool invocations.

### Phase 3: File I/O
Wrap file read/write operations.

## Troubleshooting

### "Resource limit exceeded" Errors

1. Check concurrency status: `manager.getConcurrencyStatus()`
2. Review metrics: `manager.getMetrics()`
3. Increase limits if legitimate load
4. Check for resource leaks (slots not released)

### Memory Warnings

1. Review memory snapshots: `manager.getMemorySnapshot()`
2. Check RSS growth over time
3. Consider increasing `maxRssMb` for peak loads
4. Profile heap usage with `--inspect`

### Timeout Escalations

1. Review metrics with `timeoutReached: true`
2. Increase `defaultTimeoutMs` if operations are legitimate
3. Implement progress-based cancellation
4. Consider splitting large operations

## Future Enhancements

- [ ] Adaptive timeout adjustment based on historical data
- [ ] Per-task resource quotas
- [ ] Lane priority queues (high/normal/low priority)
- [ ] Automatic lane rebalancing
- [ ] Integration with Prometheus metrics
- [ ] Dashboard/alerting UI
- [ ] Resource prediction based on task characteristics
- [ ] Automatic backoff on sustained load

## References

- OTel spans: `tools/wvo_mcp/src/telemetry/otel_spans.ts`
- Existing telemetry: `tools/wvo_mcp/src/telemetry/`
- Worker infrastructure: `tools/wvo_mcp/src/worker/`
- Logger interface: `tools/wvo_mcp/src/telemetry/logger.ts`
