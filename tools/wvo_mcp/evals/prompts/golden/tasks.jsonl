{"id": "STRATEGIZE-001", "phase": "strategize", "prompt": "You are in the STRATEGIZE phase for a task to add caching to API responses. Reframe the problem: What is the deeper problem we're solving? Consider: 1) Why do we need caching? 2) What alternatives exist? 3) What are the kill criteria?", "expected_output_criteria": ["Identifies root cause (latency? cost? load?)", "Lists 3+ alternatives (caching, CDN, query optimization, etc.)", "Defines explicit kill criteria (if X metric doesn't improve by Y%)", "Questions the problem statement (is caching the right solution?)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": true}
{"id": "STRATEGIZE-002", "phase": "strategize", "prompt": "You are strategizing a task to refactor a 2000-line file into modules. Analyze: 1) Why is the file so large? 2) What's the underlying issue (tight coupling? feature creep?)? 3) What are 3 different approaches to modularization?", "expected_output_criteria": ["Diagnoses why file grew large (not just 'it's big')", "Identifies architectural issue (coupling, SRP violation, etc.)", "Proposes 3+ approaches (by domain, by layer, by lifecycle, etc.)", "Considers do-nothing alternative with honest tradeoffs"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "STRATEGIZE-003", "phase": "strategize", "prompt": "STRATEGIZE phase: Add telemetry to a critical workflow. Reframe: 1) What decisions will this telemetry inform? 2) What's the cost of NOT having this data? 3) What are alternatives to instrumentation?", "expected_output_criteria": ["Defines decision-making use case (not just 'monitoring')", "Quantifies cost of ignorance (incident MTTR? blind debugging?)", "Lists alternatives (sampling, logs, external tools)", "Proposes hypothesis to validate with data"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": true}
{"id": "STRATEGIZE-004", "phase": "strategize", "prompt": "You're strategizing integration of an external API. Problem: API is rate-limited to 100 req/min. Reframe: 1) What's the real constraint? 2) Can we avoid API calls entirely? 3) What are architectural alternatives?", "expected_output_criteria": ["Identifies real constraint (rate limit vs data freshness vs cost)", "Explores avoiding API (caching, batch, alternative data source)", "Proposes 3+ architectures (queue, cache, fallback, multi-source)", "Defines success metrics (uptime? latency? cost?)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "SPEC-001", "phase": "spec", "prompt": "You are in the SPEC phase for adding user authentication. Define: 1) Acceptance criteria (what does 'done' look like?), 2) Out-of-scope items, 3) Success metrics, 4) Verification mapping (how will each criterion be verified?)", "expected_output_criteria": ["Lists 5+ specific acceptance criteria (not vague)", "Explicitly defines out-of-scope (what we WON'T do)", "Defines measurable success metrics (latency <X, uptime >Y%)", "Maps each criterion to verification method (test, manual check, etc.)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "SPEC-002", "phase": "spec", "prompt": "SPEC phase: You're defining acceptance criteria for a database migration. Include: 1) Zero-downtime requirement, 2) Rollback plan, 3) Data integrity checks, 4) Performance thresholds", "expected_output_criteria": ["Explicit downtime requirement (0 seconds tolerated)", "Detailed rollback steps (not just 'we can roll back')", "Specific integrity checks (checksums, row counts, FK validation)", "Quantified performance (query latency <Xms, throughput >Y qps)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": false}
{"id": "SPEC-003", "phase": "spec", "prompt": "SPEC: A task to add retry logic to API calls. Define: 1) AC for happy path (retries succeed), 2) AC for exhausted retries, 3) AC for non-retryable errors, 4) Verification for each", "expected_output_criteria": ["AC covers success case (retry succeeds within N attempts)", "AC covers failure case (exhausted retries, error surfaced)", "AC covers non-retryable (4xx errors don't retry)", "Each AC has explicit verification method (test case, manual scenario)"], "pass_threshold": 4, "complexity": "medium", "reasoning_required": false}
{"id": "SPEC-004", "phase": "spec", "prompt": "SPEC phase: Task is to optimize a slow SQL query. Define AC including: 1) Target latency, 2) Query plan requirements, 3) Index strategy, 4) How to verify in production", "expected_output_criteria": ["Quantified target (p95 latency <Xms, down from Yms)", "Query plan constraints (no full table scans, index usage)", "Index strategy defined (which columns, why)", "Production verification (EXPLAIN ANALYZE, monitoring)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "PLAN-001", "phase": "plan", "prompt": "You are in the PLAN phase for implementing feature flags. Break down: 1) Implementation steps in dependency order, 2) Time estimates per step, 3) Risks per step, 4) Verification checkpoints", "expected_output_criteria": ["5+ sequential steps with clear dependencies", "Realistic time estimates (hours, not 'quick')", "Risk identified for each step (integration, performance, etc.)", "Verification checkpoint after each step (how to know it worked)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "PLAN-002", "phase": "plan", "prompt": "PLAN: Implementing circuit breaker for external service. Plan should include: 1) Circuit breaker state machine, 2) Configuration strategy, 3) Testing approach, 4) Rollout plan", "expected_output_criteria": ["State machine defined (closed, open, half-open transitions)", "Configuration externalized (thresholds, timeouts not hardcoded)", "Test plan covers all states (happy, failure, recovery)", "Gradual rollout (canary, feature flag, monitoring)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "PLAN-003", "phase": "plan", "prompt": "PLAN phase: Refactoring a monolithic function into modules. Plan: 1) Extraction order (which pieces first?), 2) Interface design, 3) Test strategy, 4) Verification at each step", "expected_output_criteria": ["Extraction order justified (least coupled first, or most critical)", "Interfaces defined (inputs, outputs, contracts)", "Tests strategy (existing tests adapted? new tests?)", "Incremental verification (each extraction proven before next)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "PLAN-004", "phase": "plan", "prompt": "PLAN: Task to migrate from API v1 to v2 with backward compatibility. Plan must include: 1) Dual-write strategy, 2) Read switchover, 3) v1 deprecation timeline, 4) Rollback points", "expected_output_criteria": ["Dual-write phase (write to both v1 and v2, read from v1)", "Read switchover (shadow mode, then flip)", "Deprecation timeline (v1 sunset date, grace period)", "Rollback points identified (can revert at each phase)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": true}
{"id": "THINK-001", "phase": "think", "prompt": "You are in the THINK phase for adding a cache. Document: 1) Critical assumptions (cache hit rate? invalidation strategy?), 2) Edge cases (cache miss, stale data, memory pressure), 3) What could go wrong? (pre-mortem)", "expected_output_criteria": ["5+ assumptions with validation strategy for each", "10+ edge cases with handling approach", "Pre-mortem: 3+ failure modes with prevention", "Distinguishes critical (must validate) vs nice-to-have assumptions"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "THINK-002", "phase": "think", "prompt": "THINK: Task is database schema migration. Analyze: 1) Assumptions about data volume, 2) Edge cases (concurrent writes, FK violations, timeouts), 3) Pre-mortem (what if migration takes 10x longer?)", "expected_output_criteria": ["Assumptions about scale (row count, table size, write rate)", "Edge cases cover concurrency (what if user writes during migration?)", "Pre-mortem identifies time/space/correctness failure modes", "Each failure mode has mitigation (not just identified)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "IMPLEMENT-001", "phase": "implement", "prompt": "You are implementing a retry mechanism. Code should: 1) Exponential backoff, 2) Max retry limit, 3) Non-retryable error detection, 4) Structured logging. Provide implementation.", "expected_output_criteria": ["Exponential backoff implemented (delay = baseDelay * 2^attempt)", "Max retries enforced (default 3, configurable)", "Non-retryable errors handled (4xx status codes don't retry)", "Logging includes attempt number, delay, error details"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "IMPLEMENT-002", "phase": "implement", "prompt": "IMPLEMENT: Feature flag system. Requirements: 1) Flag evaluation <1ms, 2) Dynamic updates (no restart), 3) Type-safe flags, 4) Audit logging. Implement the core.", "expected_output_criteria": ["Evaluation is O(1) lookup (hash map or similar)", "Flags reload from config without restart (file watch or polling)", "Type safety (boolean, string, number with validation)", "Audit log records flag checks (user, flag, value, timestamp)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": false}
{"id": "IMPLEMENT-003", "phase": "implement", "prompt": "Implement a circuit breaker. Must: 1) Track failure rate in sliding window, 2) Transition open->half-open after timeout, 3) Thread-safe, 4) Observable (metrics/logs)", "expected_output_criteria": ["Sliding window (last N requests, not all time)", "State transitions correct (closed->open at threshold, open->half-open after timeout)", "Thread-safe (atomic operations or locks)", "Emits metrics (state, failure rate, last state change)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "IMPLEMENT-004", "phase": "implement", "prompt": "IMPLEMENT: Rate limiter using token bucket. Requirements: 1) Configurable rate and burst, 2) Thread-safe, 3) Efficient (no busy loops), 4) Returns time-until-available on rejection", "expected_output_criteria": ["Token bucket algorithm (refill rate + burst capacity)", "Thread-safe token decrement (atomic or lock)", "Efficient (sleep or timestamp check, not polling)", "On reject: returns wait time (helpful for backoff)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": false}
{"id": "VERIFY-001", "phase": "verify", "prompt": "You are in the VERIFY phase after implementing caching. Write: 1) Unit tests (hit, miss, invalidation), 2) Integration test (real cache backend), 3) Performance test (latency improvement), 4) Edge case tests (concurrent access)", "expected_output_criteria": ["Unit tests cover hit, miss, eviction, TTL", "Integration test uses real cache (Redis, Memcached)", "Performance test measures latency (compare cached vs uncached)", "Concurrency test (multiple threads, race conditions)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "VERIFY-002", "phase": "verify", "prompt": "VERIFY: Database migration completed. Verification must include: 1) Row count comparison, 2) Data integrity checks (checksums), 3) Performance validation (query latency), 4) Rollback test", "expected_output_criteria": ["Row counts match (before vs after)", "Checksums or sample data validation (integrity)", "Query performance meets spec (p95 latency <Xms)", "Rollback tested (migrate up, then down, verify original state)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "REVIEW-001", "phase": "review", "prompt": "You are in the REVIEW phase for a caching implementation. Conduct adversarial review: 1) What did we miss? 2) Where will this break in production? 3) What assumptions are wrong? 4) What gaps exist?", "expected_output_criteria": ["Identifies 5+ potential issues (not just 'looks good')", "Questions assumptions (cache hit rate realistic?)", "Finds gaps (error handling? monitoring? documentation?)", "Distinguishes blocking issues (must fix) vs improvements (nice-to-have)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "REVIEW-002", "phase": "review", "prompt": "REVIEW phase: Reviewing a database migration. Challenge: 1) Is zero-downtime actually achieved? 2) What edge cases were missed? 3) Is rollback plan realistic? 4) Production risks?", "expected_output_criteria": ["Challenges downtime claim with specific scenarios", "Identifies edge cases (concurrent writes, FK constraints, timeouts)", "Critiques rollback plan (can we actually revert? data loss?)", "Surfaces production risks (scale, monitoring, incident response)"], "pass_threshold": 3, "complexity": "high", "reasoning_required": true}
{"id": "PR-001", "phase": "pr", "prompt": "You are in the PR phase after completing a caching feature. Create: 1) Commit message (why, what, how), 2) Follow-up tasks list, 3) Rollback plan documentation", "expected_output_criteria": ["Commit message explains why (problem) not just what (solution)", "Follow-up tasks captured (deferä¸ed work from REVIEW)", "Rollback plan documented (steps, risks, verification)", "No placeholder TODOs in commit (defer to follow-up tasks)"], "pass_threshold": 3, "complexity": "low", "reasoning_required": false}
{"id": "PR-002", "phase": "pr", "prompt": "PR phase: You completed a database migration. Document: 1) Migration steps taken, 2) Deferred work (what's NOT in this PR), 3) Monitoring plan, 4) Rollback procedure", "expected_output_criteria": ["Migration steps listed (order, commands, verification)", "Deferred work explicitly listed (schema v2, performance tuning, etc.)", "Monitoring plan (metrics to watch, alert thresholds)", "Rollback procedure detailed (when to rollback, how, risks)"], "pass_threshold": 4, "complexity": "medium", "reasoning_required": false}
{"id": "MONITOR-001", "phase": "monitor", "prompt": "You are in the MONITOR phase for a caching feature deployed to production. Define: 1) Key metrics to track, 2) Alert thresholds, 3) Success criteria, 4) When to rollback", "expected_output_criteria": ["5+ metrics (cache hit rate, latency, memory, eviction rate, errors)", "Alert thresholds defined (hit rate <X%, latency >Yms)", "Success criteria (sustain hit rate >Z% for 7 days)", "Rollback criteria explicit (if hit rate <W% for 24h, rollback)"], "pass_threshold": 3, "complexity": "medium", "reasoning_required": false}
{"id": "MONITOR-002", "phase": "monitor", "prompt": "MONITOR: Database migration completed. Ongoing monitoring: 1) Performance metrics (query latency), 2) Data integrity checks, 3) Incident response plan, 4) Success definition", "expected_output_criteria": ["Performance metrics tracked (p50, p95, p99 latency)", "Data integrity (daily checksums, anomaly detection)", "Incident plan (who to page, what to check, rollback steps)", "Success defined (stable latency for 30 days, zero integrity issues)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "INTEGRATION-001", "phase": "implement", "prompt": "Implement cross-package integration: Package A calls Package B's API. Requirements: 1) Typed interface, 2) Error handling, 3) Retry logic, 4) Integration test covering both packages", "expected_output_criteria": ["Typed interface defined (TS/Zod or Pydantic)", "Error handling (network errors, validation errors, timeouts)", "Retry with backoff (transient failures)", "Integration test imports both packages, tests actual calls"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "INTEGRATION-002", "phase": "implement", "prompt": "Refactor shared logic into a utility module used by 3 packages. Must: 1) Zero breaking changes, 2) Backward compatibility tests, 3) Documentation for consumers, 4) Versioning strategy", "expected_output_criteria": ["Existing APIs preserved (new module exports same interface)", "Tests prove backward compatibility (existing callers work unchanged)", "Documentation for each consumer (how to import, examples)", "Versioning plan (semver, deprecation timeline if changes needed)"], "pass_threshold": 4, "complexity": "high", "reasoning_required": false}
{"id": "EDGE-CASE-001", "phase": "implement", "prompt": "Implement user input validation with edge cases: 1) Empty string, 2) Very long input (1MB), 3) Special characters (XSS), 4) Unicode edge cases, 5) Null/undefined", "expected_output_criteria": ["Empty string handled (reject or default)", "Large input bounded (reject >Nkb, avoid DoS)", "XSS prevention (sanitization or escaping)", "Unicode handled (emoji, RTL, combining characters)", "Null/undefined handled gracefully (not crash)"], "pass_threshold": 4, "complexity": "medium", "reasoning_required": false}
